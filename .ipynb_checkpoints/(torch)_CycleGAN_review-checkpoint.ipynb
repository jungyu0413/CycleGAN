{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d4a9537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd4e333",
   "metadata": {},
   "source": [
    "#### Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2141bc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1), # padding, keep the image size constant after next conv2d\n",
    "            nn.Conv2d(in_channels, in_channels, 3),\n",
    "            nn.InstanceNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_channels, in_channels, 3),\n",
    "            nn.InstanceNorm2d(in_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352f4aa6",
   "metadata": {},
   "source": [
    "#### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05fd5c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorResNet(nn.Module):\n",
    "    def __init__(self, in_channels, num_residual_blocks=9):\n",
    "        super(GeneratorResNet, self).__init__()\n",
    "        \n",
    "        # Inital Convolution  3*256*256 -> 64*256*256\n",
    "        out_channels=64\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.ReflectionPad2d(in_channels), # padding, keep the image size constant after next conv2d\n",
    "            nn.Conv2d(in_channels, out_channels, 2*in_channels+1),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        channels = out_channels\n",
    "        \n",
    "        # Downsampling   64*256*256 -> 128*128*128 -> 256*64*64\n",
    "        self.down = []\n",
    "        for _ in range(2):\n",
    "            out_channels = channels * 2\n",
    "            self.down += [\n",
    "                nn.Conv2d(channels, out_channels, 3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "            channels = out_channels\n",
    "        self.down = nn.Sequential(*self.down)\n",
    "        \n",
    "        # Transformation (ResNet)  256*64*64\n",
    "        self.trans = [ResidualBlock(channels) for _ in range(num_residual_blocks)]\n",
    "        self.trans = nn.Sequential(*self.trans)\n",
    "        \n",
    "        # Upsampling  256*64*64 -> 128*128*128 -> 64*256*256\n",
    "        self.up = []\n",
    "        for _ in range(2):\n",
    "            out_channels = channels // 2\n",
    "            self.up += [\n",
    "                nn.Upsample(scale_factor=2), # bilinear interpolation\n",
    "                nn.Conv2d(channels, out_channels, 3, stride=1, padding=1),\n",
    "                nn.InstanceNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "            channels = out_channels\n",
    "        self.up = nn.Sequential(*self.up)\n",
    "        \n",
    "        # Out layer  64*256*256 -> 3*256*256\n",
    "        self.out = nn.Sequential(\n",
    "            nn.ReflectionPad2d(in_channels),\n",
    "            nn.Conv2d(channels, in_channels, 2*in_channels+1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.down(x)\n",
    "        x = self.trans(x)\n",
    "        x = self.up(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a3fffb",
   "metadata": {},
   "source": [
    "#### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d319115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            # why normalize=False?\n",
    "            *self.block(in_channels, 64, normalize=False), # 3*256*256 -> 64*128*128 \n",
    "            *self.block(64, 128),  # 64*128*128 -> 128*64*64\n",
    "            *self.block(128, 256), # 128*64*64 -> 256*32*32\n",
    "            *self.block(256, 512), # 256*32*32 -> 512*16*16\n",
    "            \n",
    "            # Why padding first then convolution?\n",
    "            nn.ZeroPad2d((1,0,1,0)), # padding left and top   512*16*16 -> 512*17*17\n",
    "            nn.Conv2d(512, 1, 4, padding=1) # 512*17*17 -> 1*16*16\n",
    "        )\n",
    "        \n",
    "        self.scale_factor = 16\n",
    "    \n",
    "    @staticmethod\n",
    "    def block(in_channels, out_channels, normalize=True):\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, 4, stride=2, padding=1)]\n",
    "        if normalize:\n",
    "            layers.append(nn.InstanceNorm2d(out_channels))\n",
    "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        \n",
    "        return layers\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0009c1a2",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ea75f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_GAN = nn.MSELoss()\n",
    "criterion_cycle = nn.L1Loss()\n",
    "criterion_identity = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43143645",
   "metadata": {},
   "source": [
    "#### Initalize G and D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b95f33c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_AB = GeneratorResNet(3)\n",
    "D_B = Discriminator(3)\n",
    "\n",
    "G_BA = GeneratorResNet(3)\n",
    "D_A = Discriminator(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "225da334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "print(f'cuda: {cuda}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37a261e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    G_AB = G_AB.cuda()\n",
    "    D_B = D_B.cuda()\n",
    "    G_BA = G_BA.cuda()\n",
    "    D_A = D_A.cuda()\n",
    "    \n",
    "    criterion_GAN = criterion_GAN.cuda()\n",
    "    criterion_cycle = criterion_cycle.cuda()\n",
    "    criterion_identity = criterion_identity.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78de451",
   "metadata": {},
   "source": [
    "#### optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d828fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "lr = 0.0002\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "\n",
    "optimizer_G = torch.optim.Adam(\n",
    "    itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=lr, betas=(b1, b2))\n",
    "\n",
    "optimizer_D_A = torch.optim.Adam(\n",
    "    D_A.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "optimizer_D_B = torch.optim.Adam(\n",
    "    D_B.parameters(), lr=lr, betas=(b1, b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07e25f9",
   "metadata": {},
   "source": [
    "#### Learning Rate Scheduler Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7d14a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoches = 100\n",
    "decay_epoch = 20\n",
    "\n",
    "lambda_func = lambda epoch: 1 - max(0, epoch-decay_epoch)/(n_epoches-decay_epoch)\n",
    "\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=lambda_func)\n",
    "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=lambda_func)\n",
    "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=lambda_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c196ff",
   "metadata": {},
   "source": [
    "#### DataLoacer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c78b933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_dir, mode='train', transforms=None):\n",
    "        A_dir = os.path.join(data_dir, 'monet_jpg')\n",
    "        B_dir = os.path.join(data_dir, 'photo_jpg')\n",
    "        \n",
    "        if mode == 'train':\n",
    "            self.files_A = [os.path.join(A_dir, name) for name in sorted(os.listdir(A_dir))[:250]]\n",
    "            self.files_B = [os.path.join(B_dir, name) for name in sorted(os.listdir(B_dir))[:250]]\n",
    "        elif mode == 'test':\n",
    "            self.files_A = [os.path.join(A_dir, name) for name in sorted(os.listdir(A_dir))[250:]]\n",
    "            self.files_B = [os.path.join(B_dir, name) for name in sorted(os.listdir(B_dir))[250:301]]\n",
    "        \n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files_A)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file_A = self.files_A[index]\n",
    "        file_B = self.files_B[index]\n",
    "        \n",
    "        img_A = Image.open(file_A)\n",
    "        img_B = Image.open(file_B)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img_A = self.transforms(img_A)\n",
    "            img_B = self.transforms(img_B)\n",
    "        \n",
    "        return img_A, img_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04023e9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 지정된 경로를 찾을 수 없습니다: 'data/gan-getting-started/monet_jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5956/38806336.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m trainloader = DataLoader(\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mImageDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransforms_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5956/1631921160.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data_dir, mode, transforms)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfiles_A\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfiles_B\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 지정된 경로를 찾을 수 없습니다: 'data/gan-getting-started/monet_jpg'"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "data_dir = 'data/gan-getting-started/'\n",
    "\n",
    "transforms_ = transforms.Compose([\n",
    "   # transforms.Resize(int(256*1.12), Image.BICUBIC),\n",
    "    #transforms.RandomCrop(256, 256),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "batch_size = 5\n",
    "\n",
    "trainloader = DataLoader(\n",
    "    ImageDataset(data_dir, mode='train', transforms=transforms_),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = 0\n",
    ")\n",
    "\n",
    "testloader = DataLoader(\n",
    "    ImageDataset(data_dir, mode='test', transforms=transforms_),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    "    num_workers = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ce8cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
    "\n",
    "def sample_images(real_A, real_B, figside=1.5):\n",
    "    assert real_A.size() == real_B.size(), 'The image size for two domains must be the same'\n",
    "    \n",
    "    G_AB.eval()\n",
    "    G_BA.eval()\n",
    "    \n",
    "    real_A = real_A.type(Tensor)\n",
    "    fake_B = G_AB(real_A).detach()\n",
    "    real_B = real_B.type(Tensor)\n",
    "    fake_A = G_BA(real_B).detach()\n",
    "    \n",
    "    nrows = real_A.size(0)\n",
    "    real_A = make_grid(real_A, nrow=nrows, normalize=True)\n",
    "    fake_B = make_grid(fake_B, nrow=nrows, normalize=True)\n",
    "    real_B = make_grid(real_B, nrow=nrows, normalize=True)\n",
    "    fake_A = make_grid(fake_A, nrow=nrows, normalize=True)\n",
    "    \n",
    "    image_grid = torch.cat((real_A, fake_B, real_B, fake_A), 1).cpu().permute(1, 2, 0)\n",
    "    \n",
    "    plt.figure(figsize=(figside*nrows, figside*4))\n",
    "    plt.imshow(image_grid)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdc81e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real_A, real_B = next(iter(testloader))\n",
    "sample_images(real_A, real_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b49e0d0",
   "metadata": {},
   "source": [
    "#### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58a799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epoches): # epoch 만큼 반복\n",
    "    for i, (real_A, real_B) in enumerate(trainloader): # trainloader에서 real data 받아오면서,횟수도 받아옴\n",
    "        real_A, real_B = real_A.type(Tensor), real_B.type(Tensor)# 텐서로 전환\n",
    "        \n",
    "        # groud truth\n",
    "        out_shape = [real_A.size(0), 1, real_A.size(2)//D_A.scale_factor, real_A.size(3)//D_A.scale_factor]\n",
    "        valid = torch.ones(out_shape).type(Tensor) # real label 1로 채우기\n",
    "        fake = torch.zeros(out_shape).type(Tensor) # fake label 0으로 채우기\n",
    "        \n",
    "        \"\"\"Train Generators\"\"\"\n",
    "        # set to training mode in the begining, beacause sample_images will set it to eval mode\n",
    "        G_AB.train() # train모드\n",
    "        G_BA.train() # train모드\n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        fake_B = G_AB(real_A) # real_A로 가짜 B\n",
    "        fake_A = G_BA(real_B) # real_B로 가짜 A\n",
    "        \n",
    "        # identity loss\n",
    "        loss_id_A = criterion_identity(fake_B, real_A) #  nn.L1Loss()   # 얼룩말을 넣었을때 다시 얼굴말이 나오게하는 loss\n",
    "        loss_id_B = criterion_identity(fake_A, real_B) #  nn.L1Loss()\n",
    "        loss_identity = (loss_id_A + loss_id_B) / 2\n",
    "        \n",
    "        # GAN loss, train G to make D think it's true\n",
    "        loss_GAN_AB = criterion_GAN(D_B(fake_B), valid) # nn.MSELoss()\n",
    "        loss_GAN_BA = criterion_GAN(D_A(fake_A), valid) # nn.MSELoss()\n",
    "        loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n",
    "        \n",
    "        # cycle loss\n",
    "        recov_A = G_BA(fake_B)\n",
    "        recov_B = G_AB(fake_A)\n",
    "        loss_cycle_A = criterion_cycle(recov_A, real_A)  #  nn.L1Loss()\n",
    "        loss_cycle_B = criterion_cycle(recov_B, real_B)  #  nn.L1Loss() \n",
    "        loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n",
    "        \n",
    "        # G totol loss\n",
    "        loss_G = 5.0*loss_identity + loss_GAN + 10.0*loss_cycle\n",
    "        \n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        \"\"\"Train Discriminator A\"\"\"\n",
    "        optimizer_D_A.zero_grad()\n",
    "        \n",
    "        loss_real = criterion_GAN(D_A(real_A), valid)\n",
    "        loss_fake = criterion_GAN(D_A(fake_A.detach()), fake)\n",
    "        loss_D_A = (loss_real + loss_fake) / 2\n",
    "        \n",
    "        loss_D_A.backward()\n",
    "        optimizer_D_A.step()\n",
    "        \n",
    "        \"\"\"Train Discriminator B\"\"\"\n",
    "        optimizer_D_B.zero_grad()\n",
    "        \n",
    "        loss_real = criterion_GAN(D_B(real_B), valid)\n",
    "        loss_fake = criterion_GAN(D_B(fake_B.detach()), fake)\n",
    "        loss_D_B = (loss_real + loss_fake) / 2\n",
    "        \n",
    "        loss_D_B.backward()\n",
    "        optimizer_D_B.step()\n",
    "    \n",
    "    lr_scheduler_G.step()\n",
    "    lr_scheduler_D_A.step()\n",
    "    lr_scheduler_D_B.step()\n",
    "    \n",
    "    # test\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        test_real_A, test_real_B = next(iter(testloader))\n",
    "        sample_images(test_real_A, test_real_B)\n",
    "\n",
    "        loss_D = (loss_D_A + loss_D_B) / 2\n",
    "        print(f'[Epoch {epoch+1}/{n_epoches}]')\n",
    "        print(f'[G loss: {loss_G.item()} | identity: {loss_identity.item()} GAN: {loss_GAN.item()} cycle: {loss_cycle.item()}]')\n",
    "        print(f'[D loss: {loss_D.item()} | D_A: {loss_D_A.item()} D_B: {loss_D_B.item()}]')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_first",
   "language": "python",
   "name": "deep_first"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
